{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import numpy as np\n",
    "import src.manipulate_dataset as md\n",
    "from src import test_metrics\n",
    "import src.models as models\n",
    "from src.xai import generate_gradcam\n",
    "from src.train import tf_model_train\n",
    "from src import ecg_plot\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.config import list_physical_devices\n",
    "print('GPUs Available: ', list_physical_devices('GPU'))  # Verify GPU use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data\n",
    "#### Example for label: PACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "dataset = 'mimic-iv'  # or 'ptb-xl' (after inspection, some label annotations were manually altered for 'ptb-xl' in the original experiments)\n",
    "dataset_relative_dir = 'data/mimic-iv/'  # or 'data/ptb-xl/'\n",
    "metadata_relative_dir = 'output/metadata/'\n",
    "ecg_plots_relative_dir = 'output/imgs/'\n",
    "target_labels_dict = {\n",
    "    'pace': 1000,\n",
    "    'neg': 1000}  # Example for label: PACE, but could contain other conditions, eg.: {'wpw': 100, 'neg': 200} \n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "target_labels_list = [label for label in target_labels_dict.keys() if label!='neg']\n",
    "test_set_tf = md.tf_bal_dataset(\n",
    "    ds_name=dataset,\n",
    "    data_input_dir=dataset_relative_dir, \n",
    "    metadata_dir=metadata_relative_dir,\n",
    "    batch_size = batch_size,\n",
    "    n_samples_per_label=target_labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of input: (5000, 12), and labels: (1,)\n"
     ]
    }
   ],
   "source": [
    "# Visualization of an ECG sample\n",
    "\n",
    "# Transform to np.array\n",
    "sample_np_raw_data, sample_np_labels = md.tf_dataset_to_numpy(test_set_tf.take(1), data_switch=True, labels_switch=True)\n",
    "print(f'Dimensions of input: {sample_np_raw_data.shape[1:]}, and labels: {sample_np_labels.shape[1:]}')\n",
    "\n",
    "# Visualize with fine plotting (could also use ecg_plot.quick_plot, for fast plotting with fewer details\n",
    "ecg_plot.fine_plot(\n",
    "    signal=sample_np_raw_data[0],\n",
    "    id_label=f'Fine plot - Labels: PACE - {sample_np_labels[0]}',  # example for label: PACE\n",
    "    dpi=300,\n",
    "    save_path=ecg_plots_relative_dir,\n",
    "    show=False, save=True)  # Save locally instead of viewing inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained model\n",
    "#### Example for label: PACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from Zenodo...\n",
      "Downloaded: output/models/ecg_xplaim_PRETRAINED.zip\n"
     ]
    }
   ],
   "source": [
    "# Download .zip files from Zenodo\n",
    "\n",
    "zenodo_url = 'https://zenodo.org/records/14968732/files/ecg_xplaim.zip'\n",
    "save_path = 'output/models/ecg_xplaim_PRETRAINED.zip'\n",
    "extract_dir = 'output/models/ecg_xplaim_PRETRAINED/'\n",
    "\n",
    "print('Downloading from Zenodo...')\n",
    "response = requests.get(zenodo_url, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(save_path, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(f'Downloaded: {save_path}')\n",
    "else:\n",
    "    print(f'Failed to download. Status code: {response.status_code}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting...\n",
      "Extracted to: output/models/ecg_xplaim_PRETRAINED/\n"
     ]
    }
   ],
   "source": [
    "# Unzip the downloaded files\n",
    "print('Extracting...')\n",
    "with zipfile.ZipFile(save_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "print(f'Extracted to: {extract_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained, task-specific model version\n",
    "# Example for PACE\n",
    "model_ecg_xplaim = load_model('output/models/ecg_xplaim_PRETRAINED/inter_model/ecg_xplaim_PACE.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, load a locally trained model\n",
    "# model_ecg_xplaim = load_model('output/models/path/to/ecg_xplaim/local/model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions - diagnostic inference\n",
    "#### Example for label: PACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "default_metrics_to_report = ['recall', 'specificity', 'auc']\n",
    "metrics_decimals = 3\n",
    "labels = ['PACE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 batches completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742970789.773989    7670 service.cc:148] XLA service 0x7f5384001b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1742970789.774023    7670 service.cc:156]   StreamExecutor device (0): NVIDIA L4, Compute Capability 8.9\n",
      "2025-03-26 06:33:09.810641: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1742970790.036744    7670 cuda_dnn.cc:529] Loaded cuDNN version 90800\n",
      "2025-03-26 06:33:16.527990: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 329.06MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-26 06:33:16.528072: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 329.06MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-26 06:33:16.554720: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 329.06MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-26 06:33:16.752323: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 329.06MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-26 06:33:16.822077: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 332.06MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-26 06:33:16.822166: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 332.06MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-26 06:33:16.986731: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 332.06MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-26 06:33:17.542538: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 332.06MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-26 06:33:17.570937: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 343.31MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-03-26 06:33:17.571014: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:306] Allocator (GPU_0_bfc) ran out of memory trying to allocate 343.31MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown \u001b[1m12s\u001b[0m 69ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1742970800.596513    7670 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 969ms/step\n",
      "y_true, y_pred extracted, shapes: (2000, 1) and (2000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 06:33:35.185413: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "/opt/conda/envs/custom_dl/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    }
   ],
   "source": [
    "# Extract y_true, y_pred\n",
    "y_true = md.tf_dataset_to_numpy(test_set_tf, data_switch=False, labels_switch=True)\n",
    "y_pred = model_ecg_xplaim.predict(test_set_tf)\n",
    "print(f'y_true, y_pred extracted, shapes: {y_true.shape} and {y_pred.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Label               recall           specificity                   auc  \\\n",
      "0       PACE  0.94 (0.923, 0.954)  0.991 (0.983, 0.996)  0.992 (0.988, 0.996)   \n",
      "1  Macro Avg                 0.94                 0.991                 0.992   \n",
      "2  Micro Avg                 0.94                 0.991                 0.992   \n",
      "\n",
      "   support  \n",
      "0     1000  \n",
      "1     1000  \n",
      "2     1000  \n"
     ]
    }
   ],
   "source": [
    "# Calculate performance metrics\n",
    "metrics = test_metrics.calculate_metrics(\n",
    "    y_true=y_true, \n",
    "    y_pred=y_pred, \n",
    "    metrics_to_report=default_metrics_to_report,\n",
    "    label_names=labels,\n",
    "    round_decimals=metrics_decimals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explainability (Grad-CAM)\n",
    "#### Example for label: PACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "sample_idx = 0\n",
    "target_layer = 'conv1d_20'\n",
    "ecg_gradcam_visual_relative_dir = 'output/imgs/'\n",
    "default_color_overlay = 'Reds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Sample with labels >> y_true: [1], y_pred: [1]\n"
     ]
    }
   ],
   "source": [
    "# Produce Grad-CAM activation\n",
    "sample_x = np.expand_dims(sample_np_raw_data[sample_idx], axis=0)\n",
    "sample_y_true = sample_np_labels[sample_idx]\n",
    "sample_y_pred = model_ecg_xplaim.predict(sample_x)\n",
    "sample_y_pred = (sample_y_pred[0]>0.5).astype(int) # Convert to int (with threshold: 0.5)\n",
    "gradcam_activation = generate_gradcam(model_ecg_xplaim, sample_x, target_layer_name=target_layer, class_idx=None)\n",
    "print(f'Sample with labels >> y_true: {sample_y_true}, y_pred: {sample_y_pred}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Grad-CAM\n",
    "\n",
    "# 12-lead plot\n",
    "ecg_plot.gradcam_plot(\n",
    "    signal=sample_x[0],\n",
    "    gradcam=gradcam_activation,\n",
    "    id_label=f'Grad-CAM: PACE - y_true: {sample_y_true}, y_pred: {sample_y_pred}',\n",
    "    save_path=ecg_gradcam_visual_relative_dir,  # Must end with '/'\n",
    "    dpi=300,\n",
    "    color_overlay=default_color_overlay,\n",
    "    show=False, save=True)  # Save locally instead of viewing inline\n",
    "\n",
    "# Single lead (II) plot\n",
    "ecg_plot.gradcam_plot_single(\n",
    "    signal=sample_x[0],\n",
    "    gradcam=gradcam_activation, \n",
    "    lead_index=1,\n",
    "    id_label=f'Grad-CAM-single: PACE - y_true: {sample_y_true}, y_pred: {sample_y_pred}',\n",
    "    save_path=ecg_gradcam_visual_relative_dir,  # Must end with '/'\n",
    "    dpi=300,\n",
    "    color_overlay=default_color_overlay,\n",
    "    show=False, save=True)  # Save locally instead of viewing inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison\n",
    "#### Example against vanilla CNN model, for label: PACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "model_name = 'vanilla_CNN_PACE'\n",
    "label_dict = {'pace': 5000, 'neg': 5000}  # example for label: PACE (can be changed accordingly)\n",
    "train_ds_name = 'mimic-iv'  # Could also be 'ptb-xl'\n",
    "train_ds_dir = 'data/mimic-iv/'  # Could also be 'data/ptb-xl/'\n",
    "metadata_dir = 'output/metadata/'\n",
    "batch_size = 128  # batch_size*(train + val + test batches) must be <= total n of samples\n",
    "train_batches = 70\n",
    "val_batches = 5\n",
    "test_batches = 3\n",
    "n_epochs = 2  # This significantly affects the time required to run. Here set to a low value for a quick demo - plz change accordingly.\n",
    "models_output_dir = 'output/models/'\n",
    "model_generator = models.Simple_CNN_generator()\n",
    "default_metrics_to_report = ['recall', 'specificity', 'auc']\n",
    "metrics_decimals = 3\n",
    "pval_decimals = 4\n",
    "metrics_labels = ['PACE']  # example for label: PACE (can be changed accordingly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vanilla CNN on mimic-iv subset and save the model\n",
    "tf_model_train(\n",
    "    model_name=model_name, label_dict=label_dict,\n",
    "    train_ds_name=train_ds_name, train_ds_dir=train_ds_dir, metadata_dir=metadata_dir,\n",
    "    train_batches=train_batches, val_batches=val_batches, test_batches=test_batches,\n",
    "    n_epochs=n_epochs, batch_size=batch_size, models_output_dir=models_output_dir,\n",
    "    model_generator=model_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load locally trained vanilla CNN model\n",
    "model_vanilla_cnn = load_model('output/models/vanilla_CNN_PACE_package/model_vanilla_CNN_PACE.keras')  # Load the last saved version after completing all epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-saved, separate test set (created during training on mimic-iv subset)\n",
    "test_data_path = 'output/models/vanilla_CNN_PACE_package/test_set_vanilla_CNN_PACE.npz'\n",
    "test_data = np.load(test_data_path)\n",
    "test_x = test_data['samples']\n",
    "test_y_true = test_data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make predictions for both models (ECG-XPLAIM and vanilla CNN)\n",
    "test_y_pred_ECG_XPLAIM = model_ecg_xplaim.predict(test_x)\n",
    "test_y_pred_VANILLA_CNN = model_vanilla_cnn.predict(test_x)\n",
    "print(f'y_pred extracted for ECG-XPLAIM and vanilla CNN, shapes: {test_y_pred_ECG_XPLAIM.shape} and {test_y_pred_VANILLA_CNN.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance metrics\n",
    "\n",
    "print('Metrics for ECG-XPLAIM:')\n",
    "metrics_ECG_XPLAIM = test_metrics.calculate_metrics(\n",
    "    y_true=test_y_true, \n",
    "    y_pred=test_y_pred_ECG_XPLAIM, \n",
    "    metrics_to_report=default_metrics_to_report,\n",
    "    label_names=labels,\n",
    "    round_decimals=metrics_decimals)\n",
    "\n",
    "print('\\n')\n",
    "print('Metrics for vanilla CNN:')\n",
    "metrics_VANILLA_CNN = test_metrics.calculate_metrics(\n",
    "    y_true=test_y_true, \n",
    "    y_pred=test_y_pred_VANILLA_CNN, \n",
    "    metrics_to_report=default_metrics_to_report,\n",
    "    label_names=labels,\n",
    "    round_decimals=metrics_decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics\n",
    "\n",
    "def metric_comparison_print(metric_comparison):\n",
    "    for label, stats in metric_comparison.items():\n",
    "        print(f\" Label: {label}\")\n",
    "        print(f\"  - Metric - Model 1:  {stats['auc_model1']}\")\n",
    "        print(f\"  - Metric - Model 2:  {stats['auc_model2']}\")\n",
    "        print(f\"  - Metric - Diff:     {stats['auc_diff']}\")\n",
    "        print(f\"  - p-value:      {stats['p_value']}\")\n",
    "        print(f\"  - Better Model: {stats['better_model']}\")\n",
    "    return None\n",
    "\n",
    "auc_comparison = test_metrics.compare_auc_bootstrap(\n",
    "    y_true=test_y_true,\n",
    "    y_pred_1=test_y_pred_ECG_XPLAIM,\n",
    "    y_pred_2=test_y_pred_VANILLA_CNN,\n",
    "    label_names=metrics_labels, round_decimals = pval_decimals)\n",
    "\n",
    "recall_comparison = test_metrics.compare_recall_mcnemar(\n",
    "    y_true=test_y_true,\n",
    "    y_pred_1=test_y_pred_ECG_XPLAIM,\n",
    "    y_pred_2=test_y_pred_VANILLA_CNN,\n",
    "    label_names=metrics_labels, round_decimals = pval_decimals)\n",
    "\n",
    "specificity_comparison = test_metrics.compare_specificity_mcnemar(\n",
    "    y_true=test_y_true,\n",
    "    y_pred_1=test_y_pred_ECG_XPLAIM,\n",
    "    y_pred_2=test_y_pred_VANILLA_CNN,\n",
    "    label_names=metrics_labels, round_decimals = pval_decimals)\n",
    "\n",
    "print('Model comparison: \\n Model 1 - ECG-XPLAIM vs. Model 2 - Vanilla CNN')\n",
    "print('\\n\\n >> AUC (bootstrap) \\n')\n",
    "metric_comparison_print(auc_comparison)\n",
    "print('\\n\\n >> Recall (McNemar) \\n')\n",
    "metric_comparison_print(auc_comparison)\n",
    "print('\\n\\n >> Specificity (McNemar) \\n')\n",
    "metric_comparison_print(auc_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of file"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "custom_dl_kernel",
   "name": "workbench-notebooks.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m128"
  },
  "kernelspec": {
   "display_name": "Full DL framework (Local)",
   "language": "python",
   "name": "custom_dl_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
